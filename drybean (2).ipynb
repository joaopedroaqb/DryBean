{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zglPIeliRq89"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um modelo de Rede Neural\n",
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size) #full connected\n",
        "    self.relu = torch.nn.ReLU() #(0, infinito)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, self.output_size)\n",
        "    self.sigmoid = torch.nn.Sigmoid() #(0, 1)\n",
        "  def forward(self, x):\n",
        "    hidden = self.fc1(x)\n",
        "    relu = self.relu(hidden)\n",
        "    output = self.fc2(relu)\n",
        "    output = self.sigmoid(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "p0k0eJcXZXzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir o arquivo CSV\n",
        "df = pd.read_csv('Dry_Bean.csv')"
      ],
      "metadata": {
        "id": "zIn9F0XcRuzd",
        "outputId": "77e312c3-971f-4862-dd7f-477821b943f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c181ceceead3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Abrir o arquivo CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dry_Bean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dry_Bean.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferir o valor máximo de cada coluna\n",
        "for col in df:\n",
        "  print(col, df[col].max())"
      ],
      "metadata": {
        "id": "wScvnKdrR6qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar os valores de cada coluna para ficar entre 0 e 1\n",
        "for column in df:\n",
        "  try:\n",
        "    if df[column].max() < 1:\n",
        "      df[column] = df[column] / 1\n",
        "    elif df[column].max() < 10:\n",
        "      df[column] /= 10\n",
        "    elif df[column].max() < 100:\n",
        "      df[column] /= 100\n",
        "    elif df[column].max() < 1000:\n",
        "      df[column] /= 1000\n",
        "    elif df[column].max() < 10000:\n",
        "      df[column] /= 10000\n",
        "    elif df[column].max() < 100000:\n",
        "      df[column] /= 100000\n",
        "    elif df[column].max() < 1000000:\n",
        "      df[column] /= 1000000\n",
        "    else:\n",
        "      print('Erro')\n",
        "  except:\n",
        "    print('Exception')\n"
      ],
      "metadata": {
        "id": "YrcVIrFxSHIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ShapeFactor1'] *= 10\n",
        "df['ShapeFactor2'] *= 100"
      ],
      "metadata": {
        "id": "YcwPythsVsEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conferir novamente o valor máximo de cada coluna\n",
        "for col in df:\n",
        "  print(col, df[col].max())"
      ],
      "metadata": {
        "id": "V9Z94qoeVoju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um df separado com 7 colunas\n",
        "df2 = pd.DataFrame(columns=list(df['Class'].unique()))\n",
        "for i in range(df.shape[0]):\n",
        "  if(df['Class'][i] == \"SEKER\"):\n",
        "    df2.loc[i] = [1,0,0,0,0,0,0]\n",
        "  elif(df['Class'][i] == \"BARBUNYA\"):\n",
        "    df2.loc[i] = [0,1,0,0,0,0,0]\n",
        "  elif(df['Class'][i] == \"BOMBAY\"):\n",
        "    df2.loc[i] = [0,0,1,0,0,0,0]\n",
        "  elif(df['Class'][i] == \"CALI\"):\n",
        "    df2.loc[i] = [0,0,0,1,0,0,0]\n",
        "  elif(df['Class'][i] == \"HOROZ\"):\n",
        "    df2.loc[i] = [0,0,0,0,1,0,0]\n",
        "  elif(df['Class'][i] == \"SIRA\"):\n",
        "    df2.loc[i] = [0,0,0,0,0,1,0]\n",
        "  elif(df['Class'][i] == \"DERMASON\"):\n",
        "    df2.loc[i] = [0,0,0,0,0,0,1]\n",
        "  else:\n",
        "    df2.loc[i] = [9,9,9,9,9,9,9]"
      ],
      "metadata": {
        "id": "NVBImaf_ae5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove column Class\n",
        "df.drop('Class', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "7D1nFXrogvHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Embaralha entrada e saída\n",
        "df, df2 = shuffle(df, df2)"
      ],
      "metadata": {
        "id": "pyrSG-Eqioe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separa em treinamento e teste\n",
        "df2 = df2.astype('float64')\n",
        "df_treino = df.iloc[:-20]\n",
        "df_teste = df.iloc[-20:]\n",
        "df2_treino = df2.iloc[:-20]\n",
        "df2_teste = df2.iloc[-20:]"
      ],
      "metadata": {
        "id": "Q8kx9Nnsnptu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converte pra tensor\n",
        "entrada_treino = torch.FloatTensor(df_treino.values)\n",
        "entrada_teste = torch.FloatTensor(df_teste.values)\n",
        "saida_treino = torch.FloatTensor(df2_treino.values)\n",
        "saida_teste = torch.FloatTensor(df2_teste.values)"
      ],
      "metadata": {
        "id": "ER0LdcsAnPgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Config do modelo\n",
        "print(entrada_treino.size())\n",
        "input_size = entrada_treino.size()[1]\n",
        "hidden_size = 50\n",
        "output_size = saida_treino.size()[1]\n",
        "modelo = Net(input_size, hidden_size, output_size)\n",
        "print(modelo)\n",
        "\n",
        "# Configurações do modelo\n",
        "criterion = torch.nn.MSELoss() # Mean Square Error\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr = 0.8, momentum = 0.19) "
      ],
      "metadata": {
        "id": "h0_QpnRJohnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Treinar o modelo\n",
        "\n",
        "epochs = 5000 # Quantidade de épocas de treinamento\n",
        "\n",
        "errors = [] # Criando um array vazio para guardar os erros de cada epoca\n",
        "\n",
        "for epoch in range(0, epochs+1):\n",
        "  optimizer.zero_grad()\n",
        "  # Forward pass\n",
        "  y_pred = modelo(entrada_treino)\n",
        "  # Compute Loss\n",
        "  loss = criterion(y_pred.squeeze(), saida_treino)\n",
        "  errors.append(loss.item())\n",
        "  if epoch % 1000 == 0:\n",
        "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "  # Backward pass\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "LCRZqeE5q4vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Config de prints\n",
        "np.set_printoptions(suppress=True)\n",
        "np.set_printoptions(threshold=sys.maxsize)\n",
        "torch.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "LlOtg6QHrVnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rodar a rede com os dados de teste, os dados que a rede nunca viu\n",
        "y_pred = modelo(entrada_teste)\n",
        "print(torch.round(y_pred, decimals=2)) # valor previsto pela rede\n",
        "print(saida_teste) # valor real"
      ],
      "metadata": {
        "id": "ugVa77wmrKcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantidade de erros e acertos\n",
        "print(y_pred.argmax(1))\n",
        "print(saida_teste.argmax(1))\n",
        "erros = torch.count_nonzero(torch.sub(y_pred.argmax(1), saida_teste.argmax(1)))\n",
        "acertos = y_pred.shape[0] - erros\n",
        "print(f' Acertos: {acertos} / Erros: {erros}')"
      ],
      "metadata": {
        "id": "kmsvMyDYsPYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico evolução do erro ao longo das épocas\n",
        "errors = np.array(errors)\n",
        "plt.figure(figsize=(12, 8))\n",
        "graf02 = plt.subplot(1, 1, 1) # nrows, ncols, index\n",
        "graf02.set_title('Errors')\n",
        "plt.plot(errors, '-')\n",
        "plt.xlabel('Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7OcHC9pjyDEp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}